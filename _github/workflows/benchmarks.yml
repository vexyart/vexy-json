# this_file: .github/workflows/benchmarks.yml

name: Benchmarks

on:
  # Run benchmarks on every push to main
  push:
    branches: [ main ]
  # Run benchmarks on pull requests
  pull_request:
    branches: [ main ]
  # Manual trigger
  workflow_dispatch:
  # Daily benchmarks at 2 AM UTC
  schedule:
    - cron: '0 2 * * *'

env:
  RUST_BACKTRACE: 1
  CARGO_TERM_COLOR: always

jobs:
  benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable
        
      - name: Install cargo-criterion
        run: cargo install cargo-criterion
        
      - name: Cache dependencies
        uses: Swatinem/rust-cache@v2
        
      - name: Run lexer benchmarks
        run: |
          cargo bench --bench lexer_microbenchmarks -- --output-format json | tee lexer_bench_results.json
          
      - name: Run parser benchmarks
        run: |
          cargo bench --bench parser_microbenchmarks -- --output-format json | tee parser_bench_results.json
          
      - name: Run memory benchmarks
        run: |
          # Use shorter sample size for memory benchmarks to prevent timeout
          cargo bench --bench memory_benchmarks -- --sample-size 20 --output-format json | tee memory_bench_results.json
          
      - name: Run comprehensive benchmarks
        run: |
          cargo bench --bench parsing -- --output-format json | tee parsing_bench_results.json
          
      - name: Run comparison benchmarks
        run: |
          cargo bench --bench comparison -- --output-format json | tee comparison_bench_results.json
          
      - name: Generate benchmark report
        run: |
          echo "# Benchmark Results" > benchmark_summary.md
          echo "Generated on: $(date)" >> benchmark_summary.md
          echo "" >> benchmark_summary.md
          
          # Extract key metrics from JSON results
          echo "## Lexer Performance" >> benchmark_summary.md
          if [ -f lexer_bench_results.json ]; then
            echo "- Lexer microbenchmarks completed" >> benchmark_summary.md
          fi
          
          echo "## Parser Performance" >> benchmark_summary.md
          if [ -f parser_bench_results.json ]; then
            echo "- Parser microbenchmarks completed" >> benchmark_summary.md
          fi
          
          echo "## Memory Usage" >> benchmark_summary.md
          if [ -f memory_bench_results.json ]; then
            echo "- Memory allocation benchmarks completed" >> benchmark_summary.md
          fi
          
          echo "## Overall Performance" >> benchmark_summary.md
          if [ -f parsing_bench_results.json ]; then
            echo "- Comprehensive parsing benchmarks completed" >> benchmark_summary.md
          fi
          
          echo "## Comparison with Other Parsers" >> benchmark_summary.md
          if [ -f comparison_bench_results.json ]; then
            echo "- Comparison benchmarks completed" >> benchmark_summary.md
          fi
          
      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            *_bench_results.json
            benchmark_summary.md
            target/criterion/
            
  benchmark-comparison:
    name: Benchmark Comparison
    runs-on: ubuntu-latest
    needs: benchmarks
    if: github.event_name == 'pull_request'
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable
        
      - name: Cache dependencies
        uses: Swatinem/rust-cache@v2
        
      - name: Checkout main branch
        run: git checkout main
        
      - name: Run baseline benchmarks
        run: |
          cargo bench --bench parsing -- --save-baseline main
          
      - name: Checkout PR branch
        run: git checkout ${{ github.event.pull_request.head.sha }}
        
      - name: Run PR benchmarks
        run: |
          cargo bench --bench parsing -- --save-baseline pr
          
      - name: Install critcmp
        run: cargo install critcmp
        
      - name: Compare benchmarks
        run: |
          critcmp main pr > benchmark_comparison.txt
          
      - name: Comment benchmark results
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const comparison = fs.readFileSync('benchmark_comparison.txt', 'utf8');
            
            const body = `## Benchmark Comparison
            
            Performance comparison between main and this PR:
            
            \`\`\`
            ${comparison}
            \`\`\`
            
            - ðŸŸ¢ Green: Performance improved
            - ðŸ”´ Red: Performance degraded
            - âšª White: No significant change
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
            
  performance-regression:
    name: Performance Regression Detection
    runs-on: ubuntu-latest
    needs: benchmarks
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 2
          
      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable
        
      - name: Cache dependencies
        uses: Swatinem/rust-cache@v2
        
      - name: Get previous commit
        run: echo "PREVIOUS_COMMIT=$(git rev-parse HEAD~1)" >> $GITHUB_ENV
        
      - name: Checkout previous commit
        run: git checkout $PREVIOUS_COMMIT
        
      - name: Run previous benchmarks
        run: |
          cargo bench --bench parsing -- --save-baseline previous
          
      - name: Checkout current commit
        run: git checkout main
        
      - name: Run current benchmarks
        run: |
          cargo bench --bench parsing -- --save-baseline current
          
      - name: Install critcmp
        run: cargo install critcmp
        
      - name: Check for regressions
        run: |
          critcmp previous current > regression_check.txt
          
          # Check if there are significant regressions (>10% slower)
          if grep -q "regressed" regression_check.txt; then
            echo "REGRESSION_DETECTED=true" >> $GITHUB_ENV
          else
            echo "REGRESSION_DETECTED=false" >> $GITHUB_ENV
          fi
          
      - name: Create regression issue
        if: env.REGRESSION_DETECTED == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const regressionText = fs.readFileSync('regression_check.txt', 'utf8');
            
            const body = `## Performance Regression Detected
            
            A performance regression has been detected in commit ${{ github.sha }}.
            
            ### Benchmark Results
            
            \`\`\`
            ${regressionText}
            \`\`\`
            
            Please investigate and fix the performance regression.
            
            ### Actions to Take
            
            1. Review the changes in the problematic commit
            2. Identify the cause of the regression
            3. Implement a fix or optimize the affected code
            4. Re-run benchmarks to verify the fix
            
            This issue was automatically created by the benchmarks workflow.
            `;
            
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Performance Regression in ${context.sha.substring(0, 7)}`,
              body: body,
              labels: ['performance', 'regression', 'bug']
            });
            
      - name: Upload regression analysis
        uses: actions/upload-artifact@v4
        with:
          name: regression-analysis
          path: |
            regression_check.txt
            target/criterion/